{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tape.datasets import PrositFragmentationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrositData = PrositFragmentationDataset(\"/sdd/PrositToTapeDataConverter/LMDB\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\n",
    "    0.25 : [],\n",
    "    0.3 : [],\n",
    "    0.35 : [],\n",
    "    0.4 : [],\n",
    "    0.45 : [],\n",
    "    0.5 : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCEdata(ceDataDict:dict, Dataset: PrositFragmentationDataset)->dict:\n",
    "    #Loop each element in dataset\n",
    "    for i in tqdm(range(len(Dataset))):\n",
    "        for k in ceDataDict.keys():\n",
    "            if np.round(Dataset[i][3], 2) == np.array(k, dtype=np.float32):\n",
    "                ceDataDict[k].append(Dataset[i])\n",
    "    return ceDataDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from tape.tokenizers import TAPETokenizer\n",
    "from typing import List, Tuple, Any, Dict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tape.utils._sampler import BucketBatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrositFragmentationDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data: dict,\n",
    "                 ce: float):\n",
    "\n",
    "        tokenizer = TAPETokenizer(vocab=\"iupac\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.ce = ce\n",
    "        self.keys = [\n",
    "                     'intensities_raw',\n",
    "                     'collision_energy_aligned_normed',\n",
    "                     'precursor_charge_onehot'\n",
    "                     ]\n",
    "                     \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.data[index][:3] + tuple([np.array(self.ce, dtype=np.float32)]) + self.data[index][4:]\n",
    "\n",
    "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, input_mask, intensities_raw_true_value, collision_energy, charge = tuple(zip(*batch))\n",
    "\n",
    "        collision_energy = np.stack(collision_energy)\n",
    "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
    "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
    "        intensities_raw_true_value = torch.FloatTensor(intensities_raw_true_value)  # type: ignore\n",
    "\n",
    "        collision_energy_tensor = torch.FloatTensor(collision_energy)\n",
    "        charge_tensor = torch.FloatTensor(charge)\n",
    "\n",
    "        return {'input_ids': input_ids,\n",
    "                'input_mask': input_mask,\n",
    "                'targets': intensities_raw_true_value,\n",
    "                'collision_energy': collision_energy_tensor,\n",
    "                'charge': charge_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tape.datasets import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import multiprocessing\n",
    "#ceDataDict = getCEdata(x, PrositData)\n",
    "#pickle.dump(ceDataDict, open(\"./data/ceDataDict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce25Dataset = PrositFragmentationDataset(ceDataDict[0.25], 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 25, 22, 20, 23, 23, 26,  8, 22, 11, 10,  7,  5, 25, 17, 19, 14,\n",
       "         3]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([ 0.01465508,  0.        , -1.        ,  0.        ,  0.        ,\n",
       "        -1.        ,  0.49154934,  0.        , -1.        ,  0.01188552,\n",
       "         0.        , -1.        ,  0.5985086 ,  0.        , -1.        ,\n",
       "         0.09070827,  0.        , -1.        ,  0.09378117,  0.        ,\n",
       "        -1.        ,  0.22752479,  0.        , -1.        ,  0.12325462,\n",
       "         0.        , -1.        ,  0.14227246,  0.        , -1.        ,\n",
       "         0.1938528 ,  0.        , -1.        ,  0.13698395,  0.        ,\n",
       "        -1.        ,  0.11928167,  0.        , -1.        ,  0.15674177,\n",
       "         0.        , -1.        ,  0.3543688 ,  0.        , -1.        ,\n",
       "         0.05974996,  0.        , -1.        ,  0.5245358 ,  0.        ,\n",
       "        -1.        ,  0.02567784,  0.        , -1.        ,  1.        ,\n",
       "         0.        , -1.        ,  0.05788065,  0.        , -1.        ,\n",
       "         0.96174705,  0.03085947, -1.        ,  0.02379364,  0.        ,\n",
       "        -1.        ,  0.49606207,  0.02558984, -1.        ,  0.06030422,\n",
       "         0.        , -1.        ,  0.32320705,  0.05885963, -1.        ,\n",
       "         0.112969  ,  0.        , -1.        ,  0.01149033,  0.24599981,\n",
       "        -1.        ,  0.112293  ,  0.        , -1.        ,  0.        ,\n",
       "         0.11123852, -1.        ,  0.        ,  0.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ], dtype=float32),\n",
       " array(0.3, dtype=float32),\n",
       " array([0, 1, 0, 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce25Dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomSampler(ce25Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sampler = BucketBatchSampler(sampler, 64, False, lambda x: len(x[0]), ce25Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "        ce25Dataset,\n",
    "        num_workers=multiprocessing.cpu_count() - 1,\n",
    "        collate_fn=ce25Dataset.collate_fn,  # type: ignore\n",
    "        batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tape import ProteinBertForValuePredictionFragmentationProsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = ProteinBertForValuePredictionFragmentationProsit.from_pretrained(\"/sdd/berzelius/torch_model\")\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "    pytorch_model = pytorch_model.to(torch.device('cuda:0'))\n",
    "else:\n",
    "    use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5317 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = list()\n",
    "targets = list()\n",
    "for batch in tqdm(loader):  \n",
    "    targets.append(batch[\"targets\"].cpu().detach().numpy())\n",
    "    if use_gpu:\n",
    "        batch = {name: tensor.cuda(device=torch.device('cuda:0'), non_blocking=True)\n",
    "                 for name, tensor in batch.items()}\n",
    "    predictions.append(pytorch_model(**batch)[1].cpu().detach().numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00916206,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.3706697 ,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.03486167,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.17605817,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.04416243,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.00637203,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]], dtype=float32)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.06135187, -0.02176052, -0.02159712, ..., -0.02932831,\n",
       "         -0.02166041, -0.0138475 ],\n",
       "        [ 0.18359505, -0.0098374 , -0.01145688, ..., -0.00943738,\n",
       "         -0.00545273,  0.05913763],\n",
       "        [ 0.15024786, -0.02002238, -0.02081721, ..., -0.02579243,\n",
       "         -0.01681008, -0.00653753],\n",
       "        ...,\n",
       "        [ 0.19604029, -0.01412448, -0.01485772, ..., -0.01979962,\n",
       "         -0.01729139, -0.00649025],\n",
       "        [ 0.10406944, -0.02179089, -0.02288099, ..., -0.0273771 ,\n",
       "         -0.02491859, -0.02711992],\n",
       "        [ 0.03087524, -0.02073514, -0.02004476, ..., -0.02566377,\n",
       "         -0.010216  , -0.01909494]], dtype=float32)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchToTF_tape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-0bfa7787901b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchToTF_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcleanTapeOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchToTF_tape'"
     ]
    }
   ],
   "source": [
    "from torchToTF_tape.utils import cleanTapeOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = ProteinBertForValuePredictionFragmentationProsit.from_pretrained(model)\n",
    "    if torch.cuda.is_available():\n",
    "        use_gpu = True\n",
    "        pytorch_model = pytorch_model.to(torch.device('cuda:0'))\n",
    "    else:\n",
    "        use_gpu = False\n",
    "   \n",
    "    loader = getTorchDataLoader(lmdb, split, batch_size = batch_size)\n",
    "    predictions = list()\n",
    "    for batch in tqdm(loader):  \n",
    "        if use_gpu:\n",
    "            batch = {name: tensor.cuda(device=torch.device('cuda:0'), non_blocking=True)\n",
    "                     for name, tensor in batch.items()}\n",
    "        predictions.append(pytorch_model(**batch)[1].cpu().detach().numpy())\n",
    "    predictions = np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2, 15, 12, 20,  9, 19, 21, 20, 15, 20, 22,  8, 11, 14,  3],\n",
       "         [ 2, 14,  9, 22,  9,  9, 25, 10,  8,  5, 15, 27, 15, 14,  3],\n",
       "         [ 2, 11,  9,  9,  9, 17, 27, 27, 16, 21, 13,  5, 20, 14,  3],\n",
       "         [ 2, 13, 20, 11, 13, 23, 14, 19,  5, 13, 21, 21, 15,  5,  3],\n",
       "         [ 2, 25,  9, 22,  9, 13, 14, 25, 19,  8, 25,  9, 15, 14,  3],\n",
       "         [ 2, 22, 19, 11,  5,  5, 19, 22, 22, 25, 22, 21, 11, 21,  3],\n",
       "         [ 2, 19, 10,  9,  7, 13,  9,  7, 11, 14, 10, 10, 22, 21,  3],\n",
       "         [ 2, 19,  5, 22, 22, 15, 11, 23, 11, 22, 19,  5,  5,  8,  3],\n",
       "         [ 2, 19, 22, 20, 19, 10, 19, 14, 27, 23, 26, 16,  8, 22,  3],\n",
       "         [ 2, 15, 23,  5,  9,  8,  8, 21, 11, 11, 22, 25, 13, 14,  3],\n",
       "         [ 2, 15, 23,  9,  8, 15,  9, 28, 12, 12, 15, 15,  8, 14,  3],\n",
       "         [ 2, 11, 15, 22,  5, 25, 15, 15, 23, 12, 15, 12, 22,  8,  3],\n",
       "         [ 2,  5, 25, 22, 21, 19, 11, 21, 11,  9, 19, 12, 10, 13,  3],\n",
       "         [ 2, 20, 13, 28,  5, 20, 10, 21, 11, 23, 25, 12,  9, 14,  3],\n",
       "         [ 2, 28, 11, 11, 23, 22, 13, 20, 15, 20, 15, 14,  9, 14,  3],\n",
       "         [ 2, 25, 22, 17, 10, 10, 12, 25, 13, 20, 25, 10,  9, 14,  3],\n",
       "         [ 2, 25, 10, 17, 23, 23,  9, 21,  8,  9, 20, 11, 22, 14,  3],\n",
       "         [ 2, 22, 11,  5,  9, 21, 11, 19, 19,  5, 22,  5, 19, 21,  3],\n",
       "         [ 2, 19, 15,  5, 22, 19, 13, 20, 12, 12,  9, 25, 23, 21,  3],\n",
       "         [ 2, 11,  9,  9,  9, 17, 16, 27, 27, 21, 13,  5, 20, 14,  3],\n",
       "         [ 2, 10, 13, 15, 20,  8, 23, 14,  5, 15, 12, 20, 25, 10,  3],\n",
       "         [ 2, 25, 15, 11, 22, 25, 22, 20, 10,  9,  9, 10, 11, 21,  3],\n",
       "         [ 2, 22, 22, 15, 15,  5,  9, 17, 20, 25, 15, 27,  9, 21,  3],\n",
       "         [ 2,  5, 25, 25, 25, 12,  5, 11,  9,  8,  8, 15, 11, 21,  3],\n",
       "         [ 2, 15, 27,  9, 12, 11, 13, 13, 20, 12, 25, 22, 22, 14,  3],\n",
       "         [ 2, 25,  8, 10, 25, 21, 15, 19, 11, 11, 22, 15, 23, 23,  3],\n",
       "         [ 2,  8,  9, 10, 10, 10,  8, 21, 22, 19,  7,  5, 10, 21,  3],\n",
       "         [ 2, 14,  9, 21, 19,  9, 15, 10, 13, 20, 11,  8, 22, 25,  3],\n",
       "         [ 2, 19, 15, 27,  5, 25,  9, 13, 13,  9, 20, 15, 12, 21,  3],\n",
       "         [ 2, 25,  9, 19,  5, 22,  9, 14,  8, 19,  9, 22, 15, 21,  3],\n",
       "         [ 2,  5, 20, 27, 19, 23, 13,  9, 21,  5, 23, 15, 23, 21,  3],\n",
       "         [ 2, 14,  5, 20, 25, 11,  8, 27, 20, 28, 22,  7,  7, 14,  3],\n",
       "         [ 2,  8, 27, 11, 22, 25,  5, 15,  8,  5, 11, 23,  5, 14,  3],\n",
       "         [ 2, 11, 15, 21, 28, 25, 25, 15, 13, 17, 11, 22, 15, 25,  3],\n",
       "         [ 2,  9, 20,  9,  9, 15, 17,  8,  5, 25, 11, 10, 22, 21,  3],\n",
       "         [ 2, 19, 15, 20, 10, 28, 22, 21, 22, 13,  5, 15, 11, 13,  3],\n",
       "         [ 2, 28, 11, 12, 15,  8, 25, 25,  9, 28, 15, 25,  8, 21,  3],\n",
       "         [ 2, 12, 16, 12,  9, 17, 20, 13, 13, 12, 21,  8, 15, 14,  3],\n",
       "         [ 2,  5, 12, 17, 10,  8, 25,  7, 14, 28, 10, 13, 15, 15,  3],\n",
       "         [ 2, 15, 19,  5,  5, 14, 15,  5,  5, 10, 11, 10, 25, 21,  3],\n",
       "         [ 2, 27, 21,  9,  9,  9, 17,  9, 11, 13, 25, 20, 15, 21,  3],\n",
       "         [ 2, 23, 13,  9, 15, 15, 11, 20,  9, 25, 22, 21, 11, 21,  3],\n",
       "         [ 2,  8,  9, 15,  5, 13, 14, 28, 17,  5, 25, 22,  9, 21,  3],\n",
       "         [ 2,  5, 10, 11, 23, 22, 22, 11, 25, 13,  9,  8, 21, 21,  3],\n",
       "         [ 2,  8, 22, 26, 22, 28, 13, 17, 22, 14, 22, 17,  8,  8,  3],\n",
       "         [ 2, 20, 13, 13,  8,  8, 13, 25, 10,  8, 10, 20, 15, 21,  3],\n",
       "         [ 2, 19,  9, 28, 11,  5, 17, 20, 10,  9, 13, 22, 15,  5,  3],\n",
       "         [ 2, 28,  5, 23,  5, 15,  9,  8, 23, 25,  8, 23, 22, 21,  3],\n",
       "         [ 2, 25, 15, 17, 13, 25, 17, 25, 25, 28, 14, 25, 23, 21,  3],\n",
       "         [ 2, 22, 21, 13, 11, 25, 15,  5, 28, 22, 25, 19, 11, 14,  3],\n",
       "         [ 2, 23, 13,  9, 15, 15, 11, 20,  9, 25, 22, 21, 11, 21,  3],\n",
       "         [ 2, 15, 13, 23, 17, 25,  9, 22, 20, 15,  5,  9, 13, 21,  3],\n",
       "         [ 2,  5, 20,  9, 13,  9, 21, 23, 19, 19, 23, 17, 10, 14,  3],\n",
       "         [ 2, 25,  5,  7, 15, 15, 17, 25, 19, 13,  9, 22, 15, 21,  3],\n",
       "         [ 2, 25, 20,  8,  7, 11, 22,  7, 25, 17,  7, 15,  8, 14,  3],\n",
       "         [ 2, 22, 22, 22, 16, 22, 11, 13, 22, 27, 12, 21, 25, 14,  3],\n",
       "         [ 2, 11, 10,  9, 23,  5, 28,  7, 13,  8, 22, 27, 11, 14,  3],\n",
       "         [ 2, 22, 20,  9, 22,  5, 19, 22, 19,  5, 21, 19,  5, 21,  3],\n",
       "         [ 2, 27, 12, 11,  5, 14, 13, 13, 20, 13,  8, 11, 17, 10,  3],\n",
       "         [ 2,  8, 27, 11, 13, 20, 25,  8, 21,  8, 15,  8, 11, 14,  3],\n",
       "         [ 2, 22, 22, 14, 28, 15, 21, 23,  9, 12, 11, 22,  9, 27,  3],\n",
       "         [ 2,  8, 13, 25,  9, 17, 15,  9, 23, 20, 22, 14, 13, 14,  3],\n",
       "         [ 2, 23, 19,  5, 23,  9,  9,  5,  5, 28, 15, 25, 22, 21,  3],\n",
       "         [ 2, 22,  5, 14,  5, 17, 20,  5,  9, 15,  9, 17,  5, 28,  3]]),\n",
       " 'input_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'targets': tensor([[ 0.0099,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [ 0.0259,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [ 0.0283,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         ...,\n",
       "         [ 0.0267,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [ 0.0528,  0.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [ 0.2864,  0.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]),\n",
       " 'collision_energy': tensor([0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000]),\n",
       " 'charge': tensor([[0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  8,  5, 23, 12,  8,  9,  5, 25, 20,  5, 15, 14,  3]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([ 0.36813897,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.14776494,  0.        ,  0.        ,  0.23337084,\n",
       "         0.        ,  0.        ,  0.34552184,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.8956807 ,  0.06529374,\n",
       "         0.        ,  0.0603044 ,  0.        ,  0.        ,  0.41535375,\n",
       "         0.14685172,  0.        ,  0.08375509,  0.        ,  0.        ,\n",
       "         0.17214774,  0.        ,  0.        ,  0.33429173,  0.0717124 ,\n",
       "         0.        ,  0.02780089,  0.        ,  0.        ,  0.928853  ,\n",
       "         0.08630364,  0.        ,  0.19358736,  0.        ,  0.        ,\n",
       "         0.09300248,  0.        ,  0.        ,  0.        ,  0.22067006,\n",
       "         0.        ,  0.        ,  0.04551147,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.18415816,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ], dtype=float32),\n",
       " array(0.24739158, dtype=float32),\n",
       " array([0, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " array(0.3, dtype=float32),\n",
       " array([0, 0, 1, 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    batch_sampler = BucketBatchSampler(\n",
    "        sampler, batch_size, False, lambda x: len(x[0]), dataset)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=dataset.collate_fn,  # type: ignore\n",
    "        batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 25, 22, 20, 23, 23, 26,  8, 22, 11, 10,  7,  5, 25, 17, 19, 14,\n",
       "         3]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([ 0.01465508,  0.        , -1.        ,  0.        ,  0.        ,\n",
       "        -1.        ,  0.49154934,  0.        , -1.        ,  0.01188552,\n",
       "         0.        , -1.        ,  0.5985086 ,  0.        , -1.        ,\n",
       "         0.09070827,  0.        , -1.        ,  0.09378117,  0.        ,\n",
       "        -1.        ,  0.22752479,  0.        , -1.        ,  0.12325462,\n",
       "         0.        , -1.        ,  0.14227246,  0.        , -1.        ,\n",
       "         0.1938528 ,  0.        , -1.        ,  0.13698395,  0.        ,\n",
       "        -1.        ,  0.11928167,  0.        , -1.        ,  0.15674177,\n",
       "         0.        , -1.        ,  0.3543688 ,  0.        , -1.        ,\n",
       "         0.05974996,  0.        , -1.        ,  0.5245358 ,  0.        ,\n",
       "        -1.        ,  0.02567784,  0.        , -1.        ,  1.        ,\n",
       "         0.        , -1.        ,  0.05788065,  0.        , -1.        ,\n",
       "         0.96174705,  0.03085947, -1.        ,  0.02379364,  0.        ,\n",
       "        -1.        ,  0.49606207,  0.02558984, -1.        ,  0.06030422,\n",
       "         0.        , -1.        ,  0.32320705,  0.05885963, -1.        ,\n",
       "         0.112969  ,  0.        , -1.        ,  0.01149033,  0.24599981,\n",
       "        -1.        ,  0.112293  ,  0.        , -1.        ,  0.        ,\n",
       "         0.11123852, -1.        ,  0.        ,  0.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ], dtype=float32),\n",
       " array(0.3, dtype=float32),\n",
       " array([0, 1, 0, 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceDataDict[0.25][0][:3] + tuple([np.array(0.3, dtype=np.float32)]) + ceDataDict[0.25][0][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 0, 0, 0], dtype=uint8),)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceDataDict[0.25][0][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.3, dtype=float32)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([np.array(0.3, dtype=np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == np.array(0.32, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(TEST[0][3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (terran2.0)",
   "language": "python",
   "name": "terran2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
